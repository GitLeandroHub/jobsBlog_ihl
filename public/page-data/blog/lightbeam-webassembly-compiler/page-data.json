{"componentChunkName":"component---src-components-templates-blog-template-tsx","path":"/blog/lightbeam-webassembly-compiler/","result":{"data":{"mdx":{"frontmatter":{"author":"Jack Fransham","date_published":"June 11, 2019","image":"/images/lightbeam-webassembly-wasm-compiler.jpeg","slug":"blog/lightbeam-webassembly-compiler/","tags":["Wasm"],"blogTitle":"Introducing Lightbeam: An Optimizing Streaming WebAssembly Compiler"},"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"index\",\n  \"tags\": [\"Wasm\"],\n  \"author\": \"Jack Fransham\",\n  \"blogTitle\": \"Introducing Lightbeam: An Optimizing Streaming WebAssembly Compiler\",\n  \"slug\": \"blog/lightbeam-webassembly-compiler/\",\n  \"date_published\": \"2019-06-11T04:00:00.000Z\",\n  \"image\": \"/images/lightbeam-webassembly-wasm-compiler.jpeg\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CraneStation/lightbeam\"\n  }, \"Lightbeam\"), \" is a new streaming compiler for WebAssembly, designed to produce the best possible assembly while still being fast enough to produce assembly faster than the WebAssembly can be received over the wire.\"), mdx(\"p\", null, \"WebAssembly was designed for streaming compilation, and even from its first public release there was a streaming implementation - \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/\"\n  }, \"Firefox has had its own optimizing streaming compiler for a long time\"), \" and V8 has LiftOff.\"), mdx(\"p\", null, \"Lightbeam is similar in concept, but has a different internal mechanism which leads to surprisingly high-quality code considering the constraints, and I\\u2019ll explain how it works in this article.\"), mdx(\"h2\", null, \"Lightbeam\"), mdx(\"p\", null, \"Lightbeam is intended for use as the initial compiler in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CraneStation/lightbeam\"\n  }, \"Wasmtime\"), \" and as the main compilation engine for \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/paritytech/substrate\"\n  }, \"Substrate\"), \"\\u2019s smart contract subsystem.\"), mdx(\"p\", null, \"In relation to the latter, you might have some questions: Why do we need a compiler for our smart contracts? What even are smart contracts? We really want to put a compiler in a blockchain client? For answers to these questions and more you can check out \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://medium.com/polkadot-network/wasm-on-the-blockchain-the-lesser-evil-da8d7c6ef6bd\"\n  }, \"my article about WebAssembly on the blockchain\"), \", but it\\u2019s not particularly important for the purposes of this article.\"), mdx(\"p\", null, \"What is important is how WebAssembly works and how we can work around its limitations to produce high-quality code in a streaming compiler.\"), mdx(\"h2\", null, \"Streaming compilation\"), mdx(\"p\", null, \"So I\\u2019m not going to go too deep into this since Lin Clark has \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/\"\n  }, \"already covered this much more thoroughly\"), \" than I can, but here\\u2019s the pitch. If you want to have fast startup times for a program, you have a few options, each with their own pros and cons:\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"- Distribute the program as machine code\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Pros: Very fast, predictable performance\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cons: Massively insecure, can\\u2019t use \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://en.wikipedia.org/wiki/SSE4\"\n  }, \"microarchitecture-specific opcodes\"), \" without extra complexity and runtime checks, must distribute separate versions of the program for each target platform\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"- Distribute bytecode and use an interpreter\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Pros: Easy to implement, easy to debug, easy to add extra functionality, easy to ensure correctness, easy to write a convenient API, 100% thread- and memory-safe by default, can be ported to any platform that the host language is portable to\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cons: Slow (really, really slow)\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"- Distribute bytecode and use a JIT\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Pros: Very fast startup and execution, can lazily compile functions (so unused functions are never compiled), can take advantage of host microarchitecture, can do \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.slideshare.net/ZeroTurnaround/vladimir-ivanovjvmjitcompilationoverview-24613146\"\n  }, \"incredibly powerful optimization techniques\"), \" that are impossible with ahead-of-time compilation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cons: Easily the most complex option, no thread- or memory-safety by default, good average-case startup but without extremely careful implementation can have very bad worst-case startup time, must implement a different backend for each target architecture\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"- Distribute bytecode and use streaming compilation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Pros: Can give very good performance with good bytecode design, relatively easy to ensure worst-case startup time is low, can take advantage of host microarchitecture\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cons: Must implement a different backend for each target architecture, no thread- or memory-safety by default, need to design bytecode around constraints of streaming compilation\")), mdx(\"p\", null, \"The main reason we decided to use a streaming compiler at Parity is that the strict bounds on compilation time are necessary in the context of the blockchain - currently we use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/paritytech/wasmi\"\n  }, \"our own in-house WebAssembly interpreter\"), \".\"), mdx(\"p\", null, \"Any one of these can be combined with a slower but more-powerful compiler that works in the background as the more immediate method of execution is running the program, with execution switching to the output of the heavyweight compiler when it\\u2019s ready.\"), mdx(\"h2\", null, \"WebAssembly primer\"), mdx(\"p\", null, \"So to explain what Lightbeam does internally, I need to explain a few things about WebAssembly. WebAssembly is a weird middle-ground between a high-level language and a more traditional bytecode. It is a bytecode in that it\\u2019s a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Stack_machine\"\n  }, \"stack machine\"), \", canonically represented as a series of opcodes instead of using a text-based format, but it has many high-level features that are rarely seen in bytecodes, like having hierarchical blocks using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"block...end\"), \" that you can break out of, a separate block type for blocks that you can jump to the end of and blocks that you can jump to the start of, and an \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"if..else..end\"), \" construct instead of a using more traditional \\u201Ctest-and-jump\\u201D instruction (it \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"also\"), \" has a test-and-jump instruction, but you \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://troubles.md/posts/why-do-we-need-the-relooper-algorithm-again/\"\n  }, \"currently can\\u2019t use it to emulate if statements\"), \"). Plus, it has \\u201Clocals\\u201D, a concept similar to variables in most high-level languages. These locals are \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://troubles.md/posts/wasm-is-not-a-stack-machine/\"\n  }, \"actually more trouble than they\\u2019re worth\"), \", however, they\\u2019re more an artifact of WebAssembly\\u2019s history than a useful feature.\"), mdx(\"p\", null, \"So although WebAssembly is designed to be easily compiled and easily compiled with a streaming compiler, it\\u2019s actually pretty non-trivial to generate optimal code from WebAssembly directly. That\\u2019s why Lightbeam doesn\\u2019t.\"), mdx(\"h2\", null, \"Gotta Go Fast\"), mdx(\"p\", null, \"So, how does Lightbeam get such good code? Well, there\\u2019s lots of small optimizations that make it possible, but we start by converting to an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Static_single_assignment_form\"\n  }, \"SSA\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Control-flow_graph\"\n  }, \"CFG\"), \" intermediate representation like a \\u201Cnormal\\u201D, non-streaming compiler would. This is comparable to LLVM IR or Cranelift IR - a simpler version of the input code that allows you to perform optimizations without having to deal with as many cases. I\\u2019ll get into precisely how thi differs from WebAssembly later. The difference between this and LLVM IR is that Lightbeam\\u2019s IR conversion is streaming - we can convert a stream of WebAssembly to a stream of IR and the backend can convert a stream of IR to a stream of native code. In practice this means that we can generate native code with only one-opcode lookahead.\"), mdx(\"p\", null, \"In the backend we keep track of where values are stored, so that we don\\u2019t need to move items around unless absolutely necessary. The upshot of this is that values stay in registers as much as possible and often do not need to be spilled to memory - and when they are spilled to memory they\\u2019re spilled in order of least-recently-used. Currently we have 4 kinds of value locations: a value can be stored in memory, in a register, in a constant or as a condition code. The latter means that where many streaming compilers would emit a comparison, a conversion of the comparison\\u2019s result to an integer, a comparison of that integer to 0, and then a jump, in Lightbeam we just emit a comparison and then a jump on that condition code, just as a non-streaming compiler would. We also get constant folding for free with this method, all without sacrificing streaming.\"), mdx(\"p\", null, \"In our case we simplify \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"if..end\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"if..else..end\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"br_if\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"br_table\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"block..end\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"loop..end\"), \" constructs to a single, flat form. Instead of nested blocks like WebAssembly, we have a flat list of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Basic_block\"\n  }, \"basic blocks\"), \" which must end with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"br\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"br_if\"), \" or \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"br_table\"), \". Instead of having many ways to switch control flow, we only have 31. entering a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"block\"), \" becomes a no-op, but \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"if\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"else\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"loop\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"end\"), \" need to be converted into this form. This is luckily extremely simple in practice.\"), mdx(\"p\", null, \"One very useful fact is that there\\u2019s no way for a block to jump without also ending the block, which simplifies a lot. Unfortunately, WebAssembly does allow that, so we have some complications. Consider the following WebAssembly:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"(block (result i32)\\n    i32.const 1\\n    i32.const 2\\n    get_local 0\\n    br_if 0\\n    i32.add\\n)\\n\")), mdx(\"p\", null, \"So what this does is returns the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"2\"), \" constant from the function if local \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"0\"), \" is non-zero, and otherwise returns the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"2\"), \" constants added together. That is, the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1\"), \" is discarded \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"only if the branch is taken\"), \". In the Lightbeam IR we explicitly state which elements are dropped for each branch target, which means that it is impossible to forget to handle this case or to handle it incorrectly - a branch where nothing is discarded and a branch where something is discarded are treated the same.\"), mdx(\"p\", null, \"We also annotate each block header with the number of calls and whether it may have backwards callers - there are optimizations you can do when a block has precisely one caller2 and we can omit generating code for blocks with zero callers entirely. Because of Wasm\\u2019s approach to control flow we can\\u2019t always know ahead of time how many callers a block will have so as a backup we count the number of callers ourselves. For blocks that can have backwards callers (i.e. those generated from Wasm \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"loop\"), \" instructions, since branch instructions branch to the loop\\u2019s header), however, that doesn\\u2019t work, and so we explicitly mark any block that could have backwards callers. You can see that without making this information simple and explicit in the IR doing optimizations related to this would be prohibitively complex.\"), mdx(\"p\", null, \"The meat of the compiler comes in the form of the virtual stack. This is a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Stack_(abstract_data_type)\"\n  }, \"LIFO queue\"), \" of value locations, which can be either:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Stack: A location on the physical stack (i.e. a memory location that is an offset to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"rsp\"), \"). Since \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"rsp\"), \" can change within a function, this is stored as an offset from what \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"rsp\"), \" was at the start of the function and the real offset is recalculated each time the value is accessed.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Register: A value in a register. I go over some important subtleties related to this further down.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Immediate: A constant value, which allows us to fold constants and do optimizations like using the immediate-operand version of instructions like \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"add\"), \" instead of spilling the constant to a register first.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Condition code: A value that represents one of the bits in the FLAGS register. This means that a comparison operation followed by a \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"select\"), \" or \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br_if\"), \" can be compiled to one of the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cc\"), \" forms of the associated instructions. For example, \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"i32.lt_u\"), \" + \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"select\"), \" compiles to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cmp\"), \" + \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cmovb\"), \", the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cmp\"), \" instruction sets some flags on the CPU and the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cmovb\"), \" reads the flags and sets the corresponding register to a certain value if the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"b\"), \" flag is set. Since there\\u2019s only one FLAGS register and many things overwrite it, we spill this kind of value to a register if anything gets pushed onto the stack on top of it. In the future we\\u2019d like to be able to only spill a condition code if we actually do an operation that overwrites it.\")), mdx(\"p\", null, \"An important thing about our \\u201Cregister\\u201D type is that registers are refcounted. To see why that\\u2019s important, we have to talk about locals.\"), mdx(\"p\", null, \"In WebAssembly, there are two kinds of place that a value can be: on the (virtual) stack or in a local. You can move a value from the stack to a local with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"set_local\"), \" and from a local to the stack with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_local\"), \". There\\u2019s also \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"tee_local\"), \", which is equivalent to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"set_local\"), \" followed by \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_local\"), \"3. Anyway, for our purposes the important thing is that \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_local\"), \" cause a value to be duplicated. This also applies to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"tee_local\"), \" but we\\u2019ll ignore that for now for simplicity\\u2019s sake. If you have some system for tracking register uses, for example, where a register can be reused when it\\u2019s no longer to be possible to access the value that was previously in it, you need to refcount registers, so that you can, for example, do a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_local\"), \" followed by overwriting the value in that local without causing the old value on the stack to magically change or otherwise become invalid. This allows us to do some other optimizations though.\"), mdx(\"p\", null, \"For example, on x86 you don\\u2019t really have a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"+\"), \" operator4, you only have \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"+=\"), \". Normally you\\u2019d need to allocate a new register, copy the LHS of the operator into it and add the RHS in-place, but if the refcount on that register is precisely 1 you can operate on it in-place. Another use of refcounting in a streaming compiler is that although in straight-line code you can have aliasing values, when you start a loop (and in some other circumstances) you have to have all your locals and stack elements in unique places. To illustrate why this is, let\\u2019s use an example. Here\\u2019s a simple loop in WebAssembly:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"(func $bad_factorial (param $param i32)\\n  (local $counter i32)\\n  (local $output i32)\\n  (set_local $counter (get_local $param))\\n  (set_local $output (get_local $counter))\\n  (loop\\n    (set_local $counter\\n      (i32.sub (get_local $counter)\\n               (i32.const 1)))\\n    (set_local $output\\n      (i32.mul (get_local $output)\\n               (get_local $counter)))\\n    (br_if 0 (i32.ne (get_local $counter) (i32.const 0)))\\n  )\\n  (return (get_local $output))\\n)\\n\")), mdx(\"p\", null, \"So in this function, when the loop starts both locals point to the same place. This is bad, since after the first iteration they will have non-aliasing locations and if we generate code that looks in the same place for both variables we\\u2019ll end up returning the wrong result. We could choose arbitrary but static and non-aliasing locations for values used by blocks (in the same way that functions have a specific calling convention called SystemV) but we want to avoid moving values around if possible. So, the first time a block is called we try to set the block\\u2019s calling convention to whatever the locations of values happen to be at the first call. When we set the calling convention for the first time, we allocate the minimum number of new locations that will remove any aliasing values. This is why it\\u2019s important that we know if a block has precisely one caller: if it only has one caller then we can always keep values where they are. If there are aliasing values then that\\u2019s fine, since we know that it\\u2019s impossible for this block be called with non-aliasing values5.\"), mdx(\"p\", null, \"For a deeper explanation of Lightbeam\\u2019s IR check out the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://troubles.md/posts/wasm-is-not-a-stack-machine/\"\n  }, \"article series that lead me to develop it\"), \".\"), mdx(\"h2\", null, \"What does this mean for me?\"), mdx(\"p\", null, \"If you\\u2019re just someone who interacts with WebAssembly as a consumer - i.e. you write code that compiles to WebAssembly and the Wasm runtime is just a black box - you might be asking what this means for you. Well, this means that Wasmtime can have vastly better startup performance, and will almost certainly have much more consistent startup performance. Other than that, it\\u2019s probably something that will be mostly transparent for you. It\\u2019s the same as V8\\u2019s LiftOff or FireFox\\u2019s baseline compiler, but for Wasmtime. However, I hope this article gives an amount of insight into how this unconventional form of compiler can work.\"), mdx(\"hr\", null), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"It would technically be possible to collapse \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br_table\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br_if\"), \" into a single construct but there are optimizations that you can do for the latter that aren\\u2019t possible with the former, so we\\u2019d just end up converting it back later on. I might actually do this later since it means that we can focus optimization on just a single place (so if we get a two-target \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br_table\"), \" as input we generate code as good as for a \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br_if\"), \"), but for now they\\u2019re separate. We could even collapse \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br\"), \" into \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"br_table\"), \" with one element, giving us only one possibility to work with.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"In a \\u201Cproper\\u201D optimizing compiler that doesn\\u2019t need to support streaming compilation, you can do optimizations on blocks with more than one caller but a streaming compiler can only do these optimizations for blocks with precisely one caller. I won\\u2019t go into precisely why this is now, I\\u2019ll leave that as an exercise for the reader, but I might revisit it in a future article.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Why they didn\\u2019t have it return the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"old\"), \" value of the local is beyond me, since that\\u2019s a lot harder to emulate (requiring you to generate an extra local). The current behaviour is trivially emulateable. I presume it\\u2019s related to Wasm\\u2019s roots as a binary representation of asm.js and the fact that JavaScript allows \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"a = b = c = d\"), \", but that\\u2019s just speculation.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Technically \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"+\"), \" is a bad example since you can emulate 3-argument \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"add\"), \" with \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"lea\"), \" but bear with me here.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"We have the same problem with values that are constants as we have for aliasing values - if we return a constant for a specific variable but then this block is called with a different value for that constant then we\\u2019ll end up with the wrong result.\")));\n}\n;\nMDXContent.isMDXComponent = true;","timeToRead":9,"excerpt":"Lightbeam  is a new streaming compiler for WebAssembly, designed to produce the best possible assembly while still being fast enough to…"},"allMdx":{"edges":[{"node":{"frontmatter":{"blogTitle":"We just released ink! 4.0!","date_published":"February 08, 2023","image":"/images/qsdh5p9.jpeg","slug":"we-just-released-ink-4-0"}}},{"node":{"frontmatter":{"blogTitle":"Parity Leadership Update","date_published":"October 21, 2022","image":"/images/blog-post.png","slug":"blog/parity-leadership-update/"}}},{"node":{"frontmatter":{"blogTitle":"Transitioning Parity Ethereum to OpenEthereum DAO","date_published":"December 16, 2019","image":"/images/parity-ethereum-openethereum.jpeg","slug":"blog/parity-ethereum-openethereum-dao/"}}}]}},"pageContext":{"slug":"blog/lightbeam-webassembly-compiler/","locale":"en","hrefLang":"en-US","originalPath":"/blog/lightbeam-webassembly-compiler/","dateFormat":"MM/DD/YYYY"}},"staticQueryHashes":["1239077767","1247656359","3280999885","3280999885","4123762078","4185913137","607815487","607815487"]}